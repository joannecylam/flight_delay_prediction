{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='grade3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pickle\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prepare_Data(object):\n",
    "    def __init__(self, filename=\"flight_delays_data.csv\"):\n",
    "        self.cnt_var = ['Week', 'std_hour', 'delay_time', 'is_claim']\n",
    "        self.bin_var = ['Arrival', 'Airline']\n",
    "        self.drop_var = ['Departure', 'flight_no']\n",
    "        self.filename = filename\n",
    "\n",
    "    def normalize_df(self, df):\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        values = scaler.fit_transform(df.values)\n",
    "        return pd.DataFrame(values, columns=df.columns.tolist(), index=df.index)      \n",
    "    \n",
    "    def cvt_bin(self, df):\n",
    "        for _var in self.bin_var:\n",
    "            print \"converting bin var:\", _var\n",
    "            for item in df[_var].unique():\n",
    "                try:\n",
    "                    field_name = _var + \"_\" + item\n",
    "                    df[field_name] = df[[_var]] == item\n",
    "                except Exception as e:\n",
    "                    print e\n",
    "                    print \"value name:\", item\n",
    "        return df\n",
    "\n",
    "    def cvt_delay_time(self, df):\n",
    "        times = []\n",
    "        for t in df['delay_time']:\n",
    "            if t == \"Cancelled\":\n",
    "                times.append(100)\n",
    "            else:\n",
    "                times.append(float(t))\n",
    "        df['delay_time'] = times\n",
    "        self.delay_min = min(times)\n",
    "        self.delay_max = max(times)\n",
    "        return df\n",
    "\n",
    "    def load_raw_data(self, additional_kwargs, time_series):\n",
    "        kwargs = {}\n",
    "        if time_series:\n",
    "            kwargs.update({\n",
    "                'parse_dates': {\"dt\": ['flight_date']},\n",
    "                'infer_datetime_format': True,\n",
    "                'index_col': 'dt'\n",
    "            })\n",
    "        else:\n",
    "            kwargs.update({'index_col': 'flight_id'})\n",
    "            \n",
    "        kwargs.update(additional_kwargs)\n",
    "        df = pd.read_csv(\n",
    "            self.filename, \n",
    "            na_values=['NaN', '?','nan'], \n",
    "            **kwargs)\n",
    "        return df\n",
    "    \n",
    "    def clean_df(self, df):\n",
    "        df.drop(self.drop_var + self.bin_var, axis=1, inplace=True)\n",
    "        df = self.cvt_delay_time(df)\n",
    "        return df\n",
    "        \n",
    "    def load_data(self, additional_kwargs={}, time_series=False):\n",
    "        df = self.load_raw_data(additional_kwargs, time_series)\n",
    "        df = self.cvt_bin(df)\n",
    "        df = self.clean_df(df)\n",
    "        df = self.cvt_datetime(df)\n",
    "        df = self.normalize_df(df)\n",
    "        return df\n",
    "    \n",
    "    def cvt_datetime(self, df, dt_label=\"flight_date\"):\n",
    "        flight_dates = [datetime.datetime.strptime(str_dt, '%Y-%m-%d').date() for str_dt in df['flight_date'].values]\n",
    "        df['flight_year'] = [dt.year for dt in flight_dates]\n",
    "        df['flight_month'] = [dt.month for dt in flight_dates]\n",
    "        df['flight_day'] = [dt.day for dt in flight_dates]\n",
    "        df.drop(dt_label, axis=1, inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def build_train(self, df, label=\"delay_time\"):\n",
    "        return df.drop('delay_time', axis=1), df['delay_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd = Prepare_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting bin var: Arrival\n",
      "converting bin var: Airline\n",
      "cannot concatenate 'str' and 'float' objects\n",
      "value name: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joannelam/programs/python/python2env/lib/python2.7/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "df = ppd.load_data(additional_kwargs={}, time_series=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = ppd.build_train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=33)\n",
    "for x in [train_x, test_x, train_y, test_y]:\n",
    "    print x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(train_x, train_y)\n",
    "results = rf.predict(test_x)\n",
    "\n",
    "ma_r = mean_absolute_error(results, test_y.values) \n",
    "ms_r = mean_squared_error(results, test_y.values) \n",
    "print \"mean absolution error:\", ma_r\n",
    "print \"mean_squared_error:\", ms_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# clf = RandomForestRegressor(kernel='linear', C=1)\n",
    "scores = cross_val_score(rf, x, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8738308174287444"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(x, open('x.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y, open('y.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_{}.pkl'.format(datetime.datetime.now().strftime(\"%H%M\"), 'wb') as f:\n",
    "    pickle.dump(rf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
